{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "name": "seminar02_part2_pandas.ipynb",
    "colab": {
      "name": "Вариант_по_подготовительным_меториятиям.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_WIDdIvU9lF",
        "colab_type": "text"
      },
      "source": [
        "# Необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E3DbRpKazy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import normaltest\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score,auc, f1_score, confusion_matrix,precision_score, recall_score, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2QUbgf0j1fZ",
        "colab_type": "text"
      },
      "source": [
        "## Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1tQa1VPj4jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Просмотр данных\n",
        "def prosmotr(data):\n",
        "  pd.set_option('display.max_columns', 100) #Размеры таблицы\n",
        "  pd.set_option('display.max_rows', 100)\n",
        "  pd.set_option('precision', 2) #Регулируем количество знаков после запятой:\n",
        "  print('~~~~Содержание данных~~~~\\n', data.head())\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Размеры данных~~~\\n', data.shape)\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Названия колонок~~~\\n', data.columns)\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Информация о данных~~~\\n')\n",
        "  print(data.info())\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Наличие пропусков в данных~~~\\n', data.isna().sum())\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Количество типов в данных~~~')\n",
        "  print(data.dtypes.value_counts())\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  kateg = list(data.select_dtypes(include=['object']).columns) # Делаем список категориальных данных\n",
        "  print('~~~Категориальные данные~~~~')\n",
        "  print(kateg)\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  chislov_float = list(data.select_dtypes(include=['float64'])) #Делаем список числовых данных float\n",
        "  print('~~~Числове данные float~~~~')\n",
        "  print(chislov_float)\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  chislov_int = list(data.select_dtypes(include=['int64'])) #Делаем список числовых данных int\n",
        "  print('~~~Числове данные int~~~~')\n",
        "  print(chislov_int)\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы int64)~~~\\n', data.describe(include=['int64']))\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Основные статистические характеристики данных по каждому числовому признаку (типы float64)~~~\\n', data.describe(include=['float64']))\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Cтатистика по нечисловым признакам object ~~~\\n', data.describe(include=['object']))\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print('~~~Cтатистика по нечисловым признакам bool ~~~\\n', data.describe(include=['bool']))\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa0Ig8DYj8vJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Анализ данных\n",
        "def analyze(data):\n",
        "  num = data.columns\n",
        "  for i in num:\n",
        "    print(i.title())\n",
        "    print('~~~~~~~~~~~~~~~~~~~~~~~~~\\n')\n",
        "    print(\"mean : \", np.mean(data[i]))\n",
        "    print(\"var  : \", np.var(data[i]))\n",
        "    print(\"skew : \", skew(data[i]))\n",
        "    print(\"kurt : \", kurtosis(data[i]))\n",
        "    print(\"shapiro : \", shapiro(data[i]))\n",
        "    print(\"normaltest : \", normaltest(data[i]))\n",
        "    print('~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "    print('~~~~~~~~~~~~~~~~~~~~~~~~~\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HljyhatVxGkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## метрика\n",
        "\n",
        "from sklearn.metrics import accuracy_score,auc, f1_score, confusion_matrix,precision_score, recall_score, roc_auc_score, roc_curve\n",
        "\n",
        "def value_of_metrics(y_true, y_pred):\n",
        "    print('Accuracy: ', accuracy_score(y_true, y_pred))\n",
        "    print('Recall: ', recall_score(y_true, y_pred))\n",
        "    print('Precision: ', precision_score(y_true, y_pred))  \n",
        "    print('F1: ', f1_score(y_true, y_pred))\n",
        "    print('Roc_AUC: ', roc_auc_score(y_true, y_pred))\n",
        "    print('Confusion Matrix: ')\n",
        "    print(pd.DataFrame(confusion_matrix(y_true, y_pred)))\n",
        "    \n",
        "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.title('My DataSet')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJKcB9SiUU7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# убираем лишее\n",
        "def unpack_X_and_y(data, col):\n",
        "  return data.drop([col],  axis=1), data[col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkAWjRApUs2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# поиск лучших фич и удаляем лишнее\n",
        "def best_features(X, y):\n",
        "  #выбираем топ 10 фич\n",
        "  bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
        "  fit = bestfeatures.fit(X,y)\n",
        "  dfscores = pd.DataFrame(fit.scores_)\n",
        "  dfcolumns = pd.DataFrame(X.columns)\n",
        "  featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "  featureScores.columns = ['Specs','Score']  \n",
        "  return list(featureScores.nlargest(10,'Score')['Specs'])   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUeQFpxNxle_",
        "colab_type": "text"
      },
      "source": [
        "## По алгоритмам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2_dbhvxqMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "def fit_model(model, X, y, parameters):  \n",
        "  cross_validation = StratifiedKFold(n_splits=5)\n",
        "\n",
        "  grid_search = GridSearchCV(model,\n",
        "                              scoring='accuracy',\n",
        "                              param_grid=parameters,\n",
        "                              cv=cross_validation,\n",
        "                              verbose=1\n",
        "                            )\n",
        "\n",
        "  grid_search.fit(X, y)\n",
        "  parameters=grid_search.best_params_\n",
        "  print('Best score: {}'.format(grid_search.best_score_))\n",
        "  print('Best parameters: {}'.format(parameters))\n",
        "\n",
        "  return grid_search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guz0bB6wxvc7",
        "colab_type": "text"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3gwLhwxsmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def KNN(train, targets):\n",
        "  parameter_grid = {\n",
        "                 'n_neighbors': [2, 5, 10, 15, 20, 25],\n",
        "                 'metric': ['chebyshev', 'manhattan', 'euclidean', 'minkowski'],\n",
        "                 'algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
        "                 }\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn_trained = fit_model(knn, train, targets, parameter_grid)\n",
        "\n",
        "  return knn_trained"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILbmFZBJxzdM",
        "colab_type": "text"
      },
      "source": [
        "## BAYES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJSSUmgPx0j5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB, ComplementNB\n",
        "\n",
        "\n",
        "def Bern(train, targets):\n",
        "  parameter_grid = {\n",
        "                 'alpha': [0.001, 0.01, 0.1, 0.2, 0.5, 1.0],\n",
        "                 'binarize': [0.0, 0.2, 0.5],\n",
        "                 'fit_prior': ['True', 'False']\n",
        "                 }\n",
        "  bernoulli = BernoulliNB()\n",
        "  trained_bernoulli = fit_model(bernoulli, train, targets, parameter_grid)\n",
        "  return trained_bernoulli\n",
        "\n",
        "def Gaus(train, targets):\n",
        "  gaussian_nb = GaussianNB()\n",
        "  parameter_grid = {\n",
        "                 'var_smoothing': [1e-09, 1e-10, 1e-11, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
        "                 }\n",
        "  trained_gaussian_nb = fit_model(gaussian_nb, train, targets, parameter_grid)\n",
        "  return trained_gaussian_nb\n",
        "\n",
        "def Multi_nb(train, targets):\n",
        "  multi_nb = MultinomialNB()\n",
        "  parameter_grid = {\n",
        "                 'alpha': [0.001, 0.01, 0.1, 0.2, 0.5, 1.0],\n",
        "                 'fit_prior': ['True', 'False']\n",
        "                 }\n",
        "  trained_multi_nb = fit_model(multi_nb, train, targets, parameter_grid)\n",
        "  return trained_multi_nb\n",
        "\n",
        "def Complement_nb(train, targets):\n",
        "  complement_nb = ComplementNB()\n",
        "  parameter_grid = {\n",
        "                 'alpha': [0.001, 0.01, 0.1, 0.2, 0.5, 1.0],\n",
        "                 'fit_prior': ['True', 'False'],\n",
        "                 'norm': ['True', 'False']\n",
        "                 }\n",
        "  trained_complement_nb = fit_model(complement_nb, train, targets, parameter_grid)\n",
        "  return trained_complement_nb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YaYQRbUx3U5",
        "colab_type": "text"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7AQlTzEjmhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "def SVM(train, targets):\n",
        "    Svm = svm.SVC()\n",
        "    parameter_grid = {\n",
        "        \"C\": [1.0, 1.5, 2.0, 5.0],\n",
        "        \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "        \"shrinking\": [True, False],\n",
        "        \"decision_function_shape\": [\"ovr\", \"ovo\"],\n",
        "        \"max_iter\": [-1, 500, 1000]\n",
        "    }\n",
        "    train_Svm = fit_model(Svm, train, targets,parameter_grid)\n",
        "    return train_Svm\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubOOWVG2z1na",
        "colab_type": "text"
      },
      "source": [
        "## RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMapcC53woor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def Random(X, y, scoring='recall', cv=5):\n",
        "  parameter_grid = {\n",
        "                  \"n_estimators\": [10, 20, 30, 50, 100],\n",
        "                  \"criterion\": [\"gini\",\"entropy\"],\n",
        "                  \"max_depth\": [2, 3, 4, 5, None],\n",
        "                  \"min_samples_split\": [2, 3, 4, 5],\n",
        "                  \"min_samples_split\": [2, 3, 4, 5]\n",
        "                 }\n",
        "  classifier = RandomForestClassifier()\n",
        "  \n",
        "  grid = GridSearchCV(estimator=classifier,\n",
        "                         param_grid=parameter_grid,\n",
        "                         scoring=scoring,\n",
        "                         cv=cv,\n",
        "                         n_jobs=-1)\n",
        "  \n",
        "  grid.fit(X, y)\n",
        "  \n",
        "  return grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i15lZXBujDDa",
        "colab_type": "text"
      },
      "source": [
        "## Варианты по алгоритмам с применением поиска лучших параметров и метрик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDT59FUSjGFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## SVM\n",
        "svm_train = SVM(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w9RIfNwlXwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_of_metrics(y_test, svm_train.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH_91orAxlu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## KNN\n",
        "knn_trained=KNN(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cmXZXoDx0-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_of_metrics(y_test, knn_trained.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXBHEQUezjn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## BAYS\n",
        "bern_train = Bern(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66L9othwzzcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_of_metrics(y_test,bern_train.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0jEL4onz50a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gaus\n",
        "gaus_train = Gaus(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI0KKbp-0EKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_of_metrics(y_test,gaus_train.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv_jsAtT0Hb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Multi\n",
        "multu_train = Multi_nb(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uff7Exqm0UlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_of_metrics(y_test,multu_train.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2jb3Onh0h8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Random\n",
        "random_train = Random(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVzYOcAf0yzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_of_metrics(y_test,random_train.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}